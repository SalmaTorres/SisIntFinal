# ğŸ¤– Sistema de AnÃ¡lisis de Entrevistas (PrÃ¡ctica Integrada Avanzada)

[cite_start]Este proyecto implementa un sistema inteligente multimodal que analiza entrevistas combinando el reconocimiento facial de emociones (CNN), transcripciÃ³n y anÃ¡lisis de texto (Transformers), y anÃ¡lisis temporal (Series de Tiempo), utilizando modelos preentrenados para la integraciÃ³n inteligente[cite: 18, 20].

---

## 1. Setup del Entorno y Reproducibilidad

El sistema requiere las siguientes dependencias externas y de Python para su correcto funcionamiento.

### 1.1. Pre-requisito de Sistema (FFmpeg) âš ï¸

El mÃ³dulo de TranscripciÃ³n (ASR/Whisper) depende de la herramienta de sistema **FFmpeg** para la decodificaciÃ³n de archivos de audio. Debe instalar FFmpeg y aÃ±adir la carpeta de los ejecutables (`bin`) a la **Variable de Entorno PATH** de su sistema operativo.

### 1.2. ConfiguraciÃ³n de Python

1.  **Clonar Repositorio:**
    ```bash
    git clone [https://github.com/SalmaTorres/SisIntFinal](https://github.com/SalmaTorres/SisIntFinal)
    cd SisIntFinal
    ```
2.  **Crear y Activar Entorno Virtual:**
    ```bash
    python -m venv venv_sia
    # Para Windows (PowerShell):
    .\venv_sia\Scripts\activate.ps1
    # Para Linux/Mac:
    source venv_sia/bin/activate
    ```
3.  **Instalar Dependencias:**
    ```bash
    pip install -r requirements.txt
    ```

### 1.3. VerificaciÃ³n de MÃ³dulos (DÃ­a 1)

* [cite_start]**VerificaciÃ³n RÃ¡pida (MÃ³dulo CNN/DeepFace):** [cite: 39]
    * Asegure la existencia de `01_DATA/raw/test_face.jpg`.
    * Ejecute: `python 02_CODE/check_deepface.py` (Debe detectar una cara).
* [cite_start]**VerificaciÃ³n RÃ¡pida (MÃ³dulo ASR/Whisper):** [cite: 39]
    * Asegure la existencia de `01_DATA/raw/audio_prueba_10s.wav` (formato WAV PCM 16kHz).
    * Ejecute: `python 02_CODE/module_audio_text.py` (Debe devolver la transcripciÃ³n).

---

## 2. Modelos Preentrenados y Estrategia

[cite_start]La soluciÃ³n se basa en la integraciÃ³n de modelos preentrenados para optimizar el tiempo de desarrollo (5 dÃ­as)[cite: 20, 26, 29].

| Componente | Modelo Preentrenado Sugerido | PropÃ³sito | Requisito TÃ©cnico |
| :--- | :--- | :--- | :--- |
| **Reconocimiento Facial** | [cite_start]DeepFace / FER-2013 pretrained [cite: 24] | DetecciÃ³n y extracciÃ³n de emociones por frame. | [cite_start]Modelo CNN Preentrenado [cite: 88] |
| **TranscripciÃ³n Audio (ASR)** | [cite_start]Whisper (OpenAI) [cite: 24] | Convertir audio de video a texto. | [cite_start]Modelo ASR Preentrenado [cite: 89] |
| **AnÃ¡lisis de Texto (NLP)** | [cite_start]ROBERTa-emotion / BERT multilingual [cite: 24] | ExtracciÃ³n de emociones del texto transcrito. | [cite_start]Modelo NLP Preentrenado (Transformers) [cite: 90] |
| **AnÃ¡lisis Temporal** | [cite_start]Pandas/Series de tiempo manual [cite: 24] | DetecciÃ³n de cambios emocionales y congruencia multimodal. | [cite_start]Modelo GRU/LSTM (Series temporales) [cite: 91] |

---

## 3. Estructura del Proyecto

[cite_start]La arquitectura del proyecto sigue una estructura modular y organizada[cite: 71]:
SisIntFinal/
â”œâ”€â”€ 01_DATA/ 
â”‚   â””â”€â”€ raw/              # Videos y audios de validaciÃ³n creados por el equipo
â”œâ”€â”€ 02_CODE/
â”‚   â”œâ”€â”€ main_pipeline.py  # Script principal de ejecuciÃ³n y orquestaciÃ³n
â”‚   â””â”€â”€ module_audio_text.py # ImplementaciÃ³n de ASR y NLP
â”‚   â””â”€â”€ check_deepface.py # Script de verificaciÃ³n del mÃ³dulo CNN
â”œâ”€â”€ 03_MODEL/
â”‚   â””â”€â”€ (Archivos de modelos preentrenados si son necesarios)
â”œâ”€â”€ 04_OUTPUTS/
â”‚   â””â”€â”€ output_structure_contract.json # Contrato JSON de la interfaz multimodal
â”œâ”€â”€ 05_DOC/
â”‚   â”œâ”€â”€ Bitacora_Diaria.md   # Registro de progreso diario (Entregable DÃ­a 1)
â”‚   â””â”€â”€ Informe_Tecnico.pdf # Informe final del proyecto
â””â”€â”€ requirements.txt      # Listado de dependencias Python
## 4. EjecuciÃ³n del Sistema

Para ejecutar el pipeline completo, use el script principal `main_pipeline.py` una vez que todos los mÃ³dulos estÃ©n integrados (DÃ­a 3):

```bash
python 02_CODE/main_pipeline.py